# 无法提取日期的链接分析总结报告

## 执行时间
2025-11-06

## 一、分析结果

### 1.1 已分析的文档

分析了5个无法提取日期的文档的实际网页内容，发现以下情况：

| 文档ID | 标题 | 来源 | 分析结果 |
|--------|------|------|----------|
| 11 | California State Lottery | www.ca.gov | ✅ 有JSON-LD和文本日期，但JSON-LD解析可能有问题 |
| 3 | FAQs | www.calottery.com | ❌ 静态页面，无明确发布日期 |
| 9 | Home | www.calottery.com | ❌ 静态页面，无明确发布日期 |
| 10 | Lottery Results | jackpocket.com | ⚠️ 有文本日期（月份），但不够精确 |
| 6 | Lottery jackpots | www.cbsnews.com | ✅ 有time标签和JSON-LD，已能提取 |

### 1.2 发现的问题

1. **time标签时区格式**
   - 问题: 某些网站的time标签datetime包含时区（如 `2025-01-22T22:38:37-0800`）
   - 解决: ✅ 已改进脚本支持时区格式

2. **JSON-LD解析不完整**
   - 问题: JSON-LD可能包含嵌套结构或其他日期字段
   - 解决: ✅ 已改进脚本递归检查JSON-LD

3. **静态页面无发布日期**
   - 问题: calottery.com的FAQ、首页等静态页面没有明确的发布日期
   - 建议: 使用 `created_at` 作为备选

## 二、改进后的提取能力

### 2.1 新增支持的格式

1. **time标签时区格式**
   - `2025-01-22T22:38:37-0800`
   - `2025-01-22T22:38:37+0800`
   - `2025-01-22T22:38:37Z`

2. **JSON-LD递归检查**
   - 递归检查嵌套对象
   - 支持更多日期字段：`dateCreated`, `dateModified`, `updateDate`等

### 2.2 提取结果

**改进前后对比**:
- 改进前: 8/81 (9.9%)
- 改进后: 8/81 (9.9%)
- 虽然数量没变，但提取逻辑更健壮，能处理更多格式

## 三、无法提取的文档分析

### 3.1 主要问题来源

#### 3.1.1 calottery.com 相关文档 (25个)

**特点**:
- 主要是静态页面（FAQ、首页、游戏页面等）
- 这些页面通常没有明确的发布日期
- 内容会定期更新，但没有记录更新日期

**建议**:
- 使用 `created_at` 作为 `publish_date`
- 或者标记为"静态页面"，不显示发布日期

#### 3.1.2 Reddit Social Sentiment (11个)

**特点**:
- Reddit帖子有时间戳，但当前数据中可能没有保存
- URL格式: `https://www.reddit.com/r/subreddit/comments/...`

**建议**:
- 从Reddit API重新获取时间戳
- 或者从URL中提取帖子ID，然后查询API

#### 3.1.3 Google News Policy (7个)

**特点**:
- 新闻文章通常有发布日期
- 但可能不在保存的content中
- 需要重新抓取或从搜索结果中提取

**建议**:
- 重新抓取页面
- 或者改进Google News的提取逻辑

### 3.2 其他无法提取的文档

大部分是：
- 静态页面（无明确发布日期）
- 数据页面（显示实时数据，无发布日期）
- 搜索结果页面（无发布日期）

## 四、进一步改进建议

### 4.1 短期改进（立即实施）

1. **应用当前改进**
   ```bash
   python scripts/fix_publish_dates.py
   ```
   修复8个可以提取的文档

2. **备选方案**
   - 对于静态页面，使用 `created_at` 作为 `publish_date`
   - 创建一个脚本批量设置备选日期

### 4.2 中期改进（1周内）

1. **针对Reddit来源**
   - 从Reddit API获取时间戳
   - 或者解析Reddit URL获取帖子ID

2. **针对calottery.com**
   - 分析其HTML结构，查找可能的更新日期
   - 或者标记为静态页面，使用created_at

3. **重新抓取**
   - 对无法提取的文档启用重新抓取
   - 使用改进后的提取逻辑

### 4.3 长期改进（1个月内）

1. **改进数据摄取流程**
   - 在摄取时就提取发布日期
   - 保存完整的HTML内容以便后续分析

2. **建立规则库**
   - 为每个主要来源建立提取规则
   - 定期更新和维护

3. **使用LLM辅助**
   - 对于复杂格式，使用LLM识别发布日期
   - 提高准确率

## 五、具体行动建议

### 5.1 立即执行

1. **修复可提取的文档**
   ```bash
   python scripts/fix_publish_dates.py
   ```

2. **创建备选方案脚本**
   - 对于静态页面，使用 `created_at` 作为 `publish_date`
   - 只处理确实无法提取的文档

### 5.2 后续改进

1. **改进数据摄取流程** (`app/services/discovery/store.py`)
   - 应用相同的改进逻辑
   - 确保新摄取的文档能够正确提取

2. **针对特定来源定制**
   - Reddit: 从API获取时间戳
   - calottery.com: 标记为静态页面或查找更新日期
   - Google News: 改进提取逻辑

## 六、总结

### 6.1 成果

✅ **改进的提取逻辑**:
- 支持time标签时区格式
- 递归检查JSON-LD
- 更健壮的日期解析

✅ **分析结果**:
- 识别了无法提取的原因
- 提供了针对性的改进建议

### 6.2 限制

⚠️ **仍无法提取的文档** (73个):
- 主要是静态页面，没有明确的发布日期
- 需要使用备选方案（created_at）

### 6.3 下一步

1. 应用当前修复（8个文档）
2. 实施备选方案（73个文档使用created_at）
3. 改进数据摄取流程
4. 针对特定来源定制提取逻辑

**预期效果**: 
- 短期: 8个文档有准确的发布日期
- 中期: 81个文档都有发布日期（8个准确 + 73个使用created_at）
- 长期: 新摄取的文档能够自动提取发布日期

